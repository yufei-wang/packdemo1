---
title: "Project 3: stat302package Tutorial"
author: "Yufei Wang"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Project 3: stat302package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(stat302package)

```

以下都是copy
# Introductory

The PROJECT3 package is a final project for STAT 302. It can be used for a variety of uses including linear modeling, k-nearest-neighbors, t-tests, and Random Forest Cross Validation. To install the package from github, run the following code.


## Install Package from Github
```{r, eval=FALSE}
setwd("..")
devtools::install("stat302package")
library(YOUR_PACKAGE_NAME)
?my_pow
devtools::install_github("yufei-wang/stat302package")
library(stat302package)
?my_pow
library(stat302package)
```

# Tutorial for my_t_test()

All the tests demonstrated below use `lifeExp` data from `my_gapminder`.
# case I: alternative = "two.sided"
  \begin{align}
  H_0: \mu &= 60,\\
  H_a: \mu &\neq 60.
  \end{align}
```{r}
data("my_gapminder")
my_t_test(my_gapminder$lifeExp, alternative = "two.sided", mu = 60)
```
From the test result, we notice that the p_value is greater than 0.05. Thus, it is not statistically significant have no enough evidence to reject the null hypothesis.

# case II: alternative = "less"
  \begin{align}
  H_0: \mu &= 60,\\
  H_a: \mu &< 60.
  \end{align}
```{r}
my_t_test(my_gapminder$lifeExp, alternative = "less", mu = 60)
```
From the test result, we notice that the p_value is less than 0.05. Thus, it is not statistically significant have no enough evidence to reject the null hypothesis.

# case III: alternative = "greater"
  \begin{align}
  H_0: \mu &= 60,\\
  H_a: \mu &> 60.
  \end{align}
```{r}
my_t_test(my_gapminder$lifeExp, alternative = "greater", mu = 60)
```
From the test result, we notice that the p_value is greater than 0.05. Thus, it is not statistically significant have no enough evidence to reject the null hypothesis.


# Tutorial for my_lm()
```{r, eval=FALSE}
test <- my_lm(my_fml = lifeExp ~ gdpPercap + continent, my_data = my_gapminder)
my_coef <- test[1]
my_matrix <- cbind(1, my_gapminder$gdpPercap)
y_hat <- my_matrix %*% as.matrix(my_coef)
plot(my_gapminder$lifeExp, y_hat)
expect_is(my_lm(pop ~ gdpPercap, my_data = my_gapminder), "table")
```
As shown, we notice that the difference of `lifeExp` between two observations is an unit in `gdpPercap`. Compared to the coeffiecients of different continents, `gdpPercap` has less influence on `lifeExp` than `continent`.

# Tutorial for my_knn_cv()
```{r, eval=FALSE}
tutor_knn <- my_knn_cv(train = my_gapminder[, 3 : 4], 
                       cl = my_gapminder$continent, k_nn = 10, k_cv = 5)
```

# Tutorial for my_rf_cv()
```{r, eval=FALSE}
library(class)
library(tidyverse)
library(randomForest)
my_rf_cv <- function(k) {
  fold <- sample(rep(1:k, length = length(my_gapminder$lifeExp)))
  # data <- data.frame()
  mse <- rep(NA, k)
  # loop thru the folds
  for (i in 1:k) {
    data_train <- iris[fold != i, ] # Xi
    data_test <-  iris[fold == i, ]  # Xi star
    # Train our models
    cl_train <- my_gapminder$lifeExp[fold != i] # Yi
    cl_test <- my_gapminder$lifeExp[fold == i]  # Yi star
    model <- randomForest(lifeExp ~ gdpPercap, data = data_train, ntree = 100)
    predictions <- predict(model, data_test[, -1])
    mse[i] <- mean((predictions - cl_test)^2)
  }
  output <- mean(mse)
}

# ########################
k_vector <- c(2, 5, 10, 100)
tutor_rf <- matrix(NA, nrow = 30, ncol = 4)
for (i in 1 : length(k_vector)) {
  for (k in 1 : 30) {
    tutor_rf[k, i] <- my_rf_cv(k = k_vector[i])
  }
}
tutor_rf
```

### Note
1. Remeber to change keywords
2. check Typo
3. Adjust axis text size

## Ackowledgments 
Thanks Bryan D. Matin for his amazing teaching in Stat302.

## Introduction
This package is the project3 for Stat302 in UW. It contains four functions: 
<p>
* my_t_test
* my_lm
* my_knn_cv
* my_rf_cv
</p>
that effectively analyzes data and evaluates statistical models. It also incorporates a dataset my_gapminder taken from the famous gapminder dataset.
You can install my package through Github in the following way:
```{r install, eval=FALSE}
devtools::install_github("yinuotxie/package302")
```

To begin, we need to load the following package and the example dataset.
```{r setup}
library(package302)
library(magrittr)
library(ggplot2)
library(dplyr)
library(kableExtra)
data("my_gapminder")
```

If you are unfamiliar with my_gapminder, you can check the description of the data using:
```{r help}
?my_gapminder
```
or, you can directly view the dataset:
```{r view}
my_gapminder
```

## Tutorials
In the tutorial section, I will show you how each function works.

### my_t_test
Function, my_t_test, can be used to perform a one sample t-test. It will be very helpful when you want to know whether or not to reject the null hypothesis. I am going to demonstrate some simply t-tests here by using **lifeExp** from my_gapminder.

Here, we want to test the null hypothesis in which the mean value of lifeExp is 60. 
$$H_0: \mu = 60$$
We also want to set the significant level to 0.05.
$$\alpha = 0.05$$

***

First example -- two.tailed t-test
$$H_a: \mu \neq 60$$
```{r}
my_t_test(data = my_gapminder$lifeExp, mu = 60, alt = "two.sided")
```
From the output, we can see the t-value, degree of freedom, p-value, and the alternative hypothesis. The p-value is greater than the significant level of 0.05, so we don't reject the null hypothesis.

***

Second example -- one.tailed t-test (less)
$$H_a: \mu < 60$$
```{r}
my_t_test(data = my_gapminder$lifeExp, mu = 60, alt = "less")
```
Now, the p-value is less than the significant level of 0.05. Thus, we reject the null hypothesis and accepts the alternative hypothesis. 

***

Third example -- one.tailed t-test (greater)
```{r}
my_t_test(data = my_gapminder$lifeExp, mu = 60, alt = "greater")
```
We don't reject the null hypothesis because p-value is greater than the significant level of 0.05

### my_lm
my_lm is a very useful function when it comes to linear regression. Here, I will demonstrate a regression using **lifeExp** as your response variable and **gdpPercap** and **continent** as explanatory variables.

Note: The estimate columns displays the coefficents.
```{r message=FALSE, warning=FALSE}
my_model <- my_lm(lifeExp ~ gdpPercap + continent, data = my_gapminder)
my_model
```
Interpretation of coefficient for gdpPercap: we notice that coefficient for gdpPercap (0.00045) has postive value. Thus, we can interpret it as that the lifeExp increases 0.00045 as gpdPercap increases one unit.

***
We can also have a hythothesis test on gdpPercap coefficient. 
We first need to set a $H_0$ and a $H_a$.
$$H_0: coef = 0$$
$$H_0: coef \neq 0$$
Then, we will test it using the significant level of 0.05.
$$ \alpha = 0.05$$
We already know the p-value from the table above. <br>
We can see that the p-value is much smaller than the significant value, so we can reject the null hypothesis and accect the alternative one. 

***
Next, we want to how well our model can do in prediction. We need to pull out some models out first: x -- explanatory variable and y -- response varible.
```{r}
object <- lifeExp ~ gdpPercap + continent
model <- model.frame(object, my_gapminder)
# extract x 
x <- model.matrix(object, my_gapminder)
# extract y
y <- model.response(model) %>% as.matrix()
```
We can also visuliaze the actual value and the fitted value. 
```{r fig.align="center", fig.width=7, fig.height=5}
# fitted value
# y_hat = x * Beta + se
my_lifeExp <- x %*% my_model$Estimate + my_model$Std.Error
my_df <- data.frame("actual" = my_gapminder$lifeExp, "fitted" = my_lifeExp,
                    "color" = my_gapminder$continent) 
my_df %>%
  ggplot(aes(x = fitted, y = actual, color = color)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  coord_flip() +    
  labs(title = "Actual vs. Fitted Values", x = "Fitted Values", y = "Actual Values",
       color = "Continent") +
  theme_classic(base_size = 18) +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = "floralwhite"),
        legend.title = element_text(hjust = 0.5),
        legend.position = c(.3, 1),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.margin = margin(6, 6, 6, 6),
        legend.box.background = element_rect(colour = "cyan"))
```
<br>
By coloring the continents, we can see that the fitted values have really good linear relationships with the actual values in Europe and Oceania, but not in other continents. Therefore, our linear model works only in certain continents. In order to make the model more accurate, we may need to apply other regressions methods, such as polynomial. 

### my_knn_cv 
my_knn_cv is a very useful in prediction using k nearest neighbor methods. It also train and evaluate the model by cross-validation. Here, I will show you how to predict output class continent using covariates gdpPercap and lifeExp from my_gapminder data.
We first need to pull our train and cl data out. 
```{r}
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
```
<br>
Before doing the predictions, we have to know how cross-validations work. Cross-validatoin will split the data into **k** different folds. Then **k-1** folds will be used to train the model and the fold left will be used to test the model.
So, cross-validation is very useful to evaluate our model. Once we have the model with a reasonable estimate of our out-of-sample test-error, we can use the full data to train our final predictive model. 
<br>
Now, we are going to do the predictions ten times with k_cv = 5 and different k_nn (number of neighbors) values each time. 
```{r}
result <- matrix(NA, nrow = 10, ncol = 2)
rownames(result) <- c(1:10)
for (i in 1:10) {
  output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = 5)
  # cv misclassfication rate
  result[i, 1] <- output$cv_error
  # training misclassification rate
  result[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(4)
}
result <- data.frame("Number of neighbors" = c(1:10), 
                     "cv misclassification rate" = result[, 1],
                     "training misclassification rate" = result[, 2])
kable_styling(kable(result))
```
The table can tell us a lot of information. According to the table, if we decide to choose the model based on the training misclassification rate, we will choose the model with the smallest rate, which is k_nn = 1. However, if we choose the model based on cv misclassification, we will choose k_nn = 10. In practice, I will probably choose the model with 5 or 6 neighbors because in those cases, both the cv and the training misclassification rate are in the acceptable range. However, our model is not very accurate because it has about 50 percent failures no matter how many folds and neighbors we choose. 

### my_rf_cv 
my_rf_cv is a powerful tool to predict data by using random forest methods and cross-validation. Here, we are using this function to predict lifeExp in each country from the covariate gdpPercap. 
We will do the demonstration by setting our k equal to 2, 5, and 10. For each k, we will run the functions 30 times.
```{r}
#Iterate through k in c(2, 5, 10):
#For each value of k, run your function 30 times.
#For each of the 30 iterations, store the CV estimated MSE.
cv_error <- matrix(NA, nrow = 90, ncol = 2)
cv_error[, 1] <- rep(c(2, 5, 10), each = 30)
# rows begin at 1
row <- 1
for(k in c(2, 5, 10)) {
  for(i in 1:30) {
    cv_error[row, 2] <- my_rf_cv(k)
    row <- row + 1
  }
}
```

To better visualize the estimated MSE, we can plot the data in boxplot.
```{r fig.align="center", fig.height=7, fig.width=7}
my_df <- data.frame("k" = cv_error[, 1], "mse" = cv_error[, 2])
my_df %>% 
  ggplot(aes(x = factor(k), y = mse, fill = factor(k))) +
  geom_boxplot() +
  labs(title = "MSE for K folds", x = "Number of Folds", y = "MSE", 
       fill = "Number of Folds") +
  theme_classic(base_size = 18) +
  theme(plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill = "floralwhite"),
        legend.title = element_text(hjust = 0.5, size = 15),
        legend.margin = margin(6, 6, 6, 6))
```
We can also caculate the mean and standard deviation of mse for each k. We will display the results in a table.
```{r}
mse_sum <- my_df %>% 
  group_by(k) %>%
  summarise(mean = mean(mse), sd = sd(mse))
kable_styling(kable(mse_sum))
```
From the boxplots, we can see that the range of MSE decreases and the median increases as k increases. We can also observe the same trends in the table -- mean increases and standard deviation decreases as k increases. It occurs because as the number of folds icrease, we are able to train the model with more data and evaluate it more times. More data as training data can increase the accurage of prediction and more evaluations can decrease the variation of MSE. 
