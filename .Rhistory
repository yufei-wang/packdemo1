usethis::use_test("my_rf_cv")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
usethis::use_testthat()
usethis::use_travis()
use_travis()
devtools::check()
#' \item{gdpPercap}{per-capita GDP}
#' }
#'
#' \source
#' https://github.com/jennybc/gapminder
#'
#'#' @examples
#' head(my_gapminder)
#'
#' The data were collected by Jennifer Bryan.
"my_gapminder
devtools::check()
#' \item{gdpPercap}{per-capita GDP}
#' }
#'
#' \source
#' https://github.com/jennybc/gapminder
#'
#'#' @examples
#' head(my_gapminder)
#'
#' The data were collected by Jennifer Bryan.
"my_gapminder"
devtools::check()
devtools::check()
source('~/Desktop/STAT302/projects/project3/stat302package/R/my_rf_cv.R')
devtools::check()
devtools::check()
usethis::use_travis()
usethis::use_travis()
usethis::use_coverage()
devtool::check()
devtools::check()
devtools::check()
usethis::use_test("my_t_test")
usethis::use_test("my_lm")
my_gapminder
Check
result <-as.table(result)
my_lm <- function(formula, data){
X <- model.matrix(formula, data)
my_model <- model.frame(formula, data)
Y <- model.response(my_model)
df <- nrow(data) - ncol(X)
#Calculate intercept
beta <- solve(t(X) %*% X) %*% t(X) %*%
# calculates variance
sigma_2 <- sum((Y - X %*% beta)^2/df)
#Calculate standard error
se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#Calculate t value and p value
t <- (beta - 0)/se
p_val <- 2*pt(abs(t), df, lower=FALSE)
# make table
result <- cbind(beta, se, t_value, pr)
colnames(result) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)")
result <-as.table(result)
return(result)
}
my_lm <- function(formula, data){
X <- model.matrix(formula, data)
my_model <- model.frame(formula, data)
Y <- model.response(my_model)
df <- nrow(data) - ncol(X)
#Calculate intercept
beta <- solve(t(X) %*% X) %*% t(X) %*%
# calculates variance
sigma_2 <- sum((Y - X %*% beta)^2/df)
#Calculate standard error
se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#Calculate t value and p value
t <- (beta - 0)/se
p_val <- 2*pt(abs(t), df, lower=FALSE)
# make table
result <- cbind(beta, se, t_value, pr)
colnames(result) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)")
result <-as.table(result)
return(result)
}
my_lm <- function(formula, data){
X <- model.matrix(formula, data)
my_model <- model.frame(formula, data)
Y <- model.response(my_model)
df <- nrow(data) - ncol(X)
#Calculate intercept
beta <- solve(t(X) %*% X) %*% t(X) %*%
# calculates variance
sigma_2 <- sum((Y - X %*% beta)^2/df)
#Calculate standard error
se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#Calculate t value and p value
t <- (beta - 0)/se
p_val <- 2*pt(abs(t), df, lower=FALSE)
# make table
result <- cbind(beta, se, t_value, pr)
colnames(result) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)")
result <-as.table(result)
return(result)
}
knitr::opts_chunk$set(echo = TRUE)
# my_lm <- function(formula, data){
#   X <- model.matrix(formula, data)
#   my_model <- model.frame(formula, data)
#   Y <- model.response(my_model)
#   df <- nrow(data) - ncol(X)
#   beta <- solve(t(X) %*% X) %*% t(X) %*% Y
#   sigma_2 <- sum((Y - X %*% beta)^2/df)
#   se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#   t <- (beta - 0)/se
#   p_val <- 2*pt(abs(t), df, lower=FALSE)
#   # make table
#   se_1 <- matrix(0, nrow = 2, ncol = 1)
#   rownames(se_1[]) < c("(Intercept", "gear")
#   se_1[1]  <- se[1]
#   se_1[2] <-  se[2]
#   result <- cbind(beta, se_1, t, p_val)
#   colnames(result) <- c("Estimate", "Std. Error", "t value", "Pr(>|t|)")
#   as.table(result)
# }
my_lm <- function(formula, data){
X <- model.matrix(formula, data)
my_model <- model.frame(formula, data)
Y <- model.response(my_model)
df <- nrow(data) - ncol(X)
#Calculate intercept
beta <- solve(t(X) %*% X) %*% t(X) %*%
# calculates variance
sigma_2 <- sum((Y - X %*% beta)^2/df)
#Calculate standard error
se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#Calculate t value and p value
t <- (beta - 0)/se
p_val <- 2*pt(abs(t), df, lower=FALSE)
# make table
result <- cbind(beta, se, t_value, pr)
colnames(result) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)")
result <-as.table(result)
return(result)
}
my_lm(formula = mpg ~ gear, data = mtcars)
result
result.mat
# my_lm <- function(formula, data){
#   X <- model.matrix(formula, data)
#   my_model <- model.frame(formula, data)
#   Y <- model.response(my_model)
#   df <- nrow(data) - ncol(X)
#   beta <- solve(t(X) %*% X) %*% t(X) %*% Y
#   sigma_2 <- sum((Y - X %*% beta)^2/df)
#   se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#   t <- (beta - 0)/se
#   p_val <- 2*pt(abs(t), df, lower=FALSE)
#   # make table
#   se_1 <- matrix(0, nrow = 2, ncol = 1)
#   rownames(se_1[]) < c("(Intercept", "gear")
#   se_1[1]  <- se[1]
#   se_1[2] <-  se[2]
#   result <- cbind(beta, se_1, t, p_val)
#   colnames(result) <- c("Estimate", "Std. Error", "t value", "Pr(>|t|)")
#   as.table(result)
# }
my_lm <- function(formula, data){
X <- model.matrix(formula, data)
my_model <- model.frame(formula, data)
Y <- model.response(my_model)
df <- nrow(data) - ncol(X)
#Calculate intercept
beta <- solve(t(X) %*% X) %*% t(X) %*%
# calculates variance
sigma_2 <- sum((Y - X %*% beta)^2/df)
#Calculate standard error
se <- diag(sqrt(sigma_2 * solve(t(X) %*% X)))
#Calculate t value and p value
t <- (beta - 0)/se
p_val <- 2*pt(abs(t), df, lower=FALSE)
# make table
result <- cbind(beta, se, t_value, pr)
colnames(result) <- c("Estimate", "Std.Error", "t.value", "Pr(>|t|)")
result <-as.table(result)
return(result)
}
my_lm(formula = mpg ~ gear, data = mtcars)
lm_1 <- lm(formula = mpg ~ gear, data = mtcars)
summary(lm_1)
lm_1$coefficients
summary(lm_1)
You can see the vignette by using the following code:
devtools::install_github("yufei-wang/stat302package", build_vignette = TRUE, build_opts = c())
library(stat302package)
# Use this to view the vignette in the Demo HTML help
help(package = "stat302package", help_type = "html")
# Use this to view the vignette as an isolated HTML file
utils::browseVignettes(package = "stat302package")
train <- my_gapminder[, 3 : 4]
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / nrow(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / nrow(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
rownames(result) <- c(1:10)
kable_styling(kable(result))
library(stat302package)
library(stats)
library(magrittr)
library(dplyr)
library(class)
library(randomForest)
library(kableExtra)
data("my_gapminder")
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
rownames(result) <- c(1:10)
kable_styling(kable(result))
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
#rownames(result) <- c(1:10)
kable_styling(kable(result))
train <- my_gapminder[, 3 : 4]
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder[, 3 : 4]
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(3)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder[, 3 : 4]
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(3)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create emmpty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(3)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"cv misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create empty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(3)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"CV misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder[, 3:4]
cl <- my_gapminder$continent
k_cv = 5
#create empty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(3)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"CV misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
train <- my_gapminder %>% select(gdpPercap, lifeExp)
cl <- my_gapminder$continent
k_cv = 5
#create empty matrix to save result
result.mat <- matrix(NA, 10, 2)
for (i in 1:10) {
output <- my_knn_cv(train = train, cl = cl, k_nn = i, k_cv = k_cv)
# record training misclassfication rate
result.mat[i, 2] <- (sum(output$class != cl) / length(cl)) %>% round(5)
# record CV misclassfication rate
result.mat[i, 1] <- output$cv_err
}
result <- data.frame("Number of neighbors" = c(1:10),
"CV misclassification rate" = result.mat[, 1],
"training misclassification rate" = result.mat[, 2])
kable_styling(kable(result))
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err <- matrix(NA, 90, 2)
cv_error[, 1] <- rep(k_val, 30)
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err <- matrix(NA, 90, 2)
cv_err[, 1] <- rep(k_val, 30)
#initiate j
j <- 1
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_error[i, 2] <- my_rf_cv(k)
i <- i + 1
}
}
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err <- matrix(NA, 90, 2)
cv_err[, 1] <- rep(k_val, 30)
#initiate j
j <- 1
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_err[i, 2] <- my_rf_cv(k)
i <- i + 1
}
}
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err <- matrix(NA, 90, 2)
cv_err[, 1] <- rep(k_val, 30)
#initiate j
j <- 1
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_err[i, 2] <- my_rf_cv(k)
i <- i + 1
}
}
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err.mat <- matrix(NA, 90, 2)
cv_err.mat[, 1] <- rep(k_val, 30)
#initiate j
i <- 1
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_err.mat[i, 2] <- my_rf_cv(k)
i <- i + 1
}
}
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err.mat <- matrix(NA, 90, 2)
cv_err.mat[, 1] <- rep(k_val, 30)
#initiate j
i <- 1
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_err.mat[i, 2] <- my_rf_cv(k)
}
}
#create matrix to store cv error
k_val <- c(2, 5, 10)
cv_err.mat <- matrix(NA, 90, 2)
cv_err.mat[, 1] <- rep(k_val, 30)
#Iterate through k in c(2, 5, 10):
for(k in k_val) {
#For each value of k, run your function 30 times.
for(i in 1:30) {
#For each of the 30 iterations, store the CV estimated MSE.
cv_err.mat[i, 2] <- my_rf_cv(k)
}
}
cv.err <- data.frame("k" = cv_err.mat[, 1], "mse" = cv_err.mat[, 2])
cv.err%>%
ggplot(aes(x = factor(k), y = mse, fill = factor(k))) +
geom_boxplot() +
labs(title = "MSE for K folds", x = "Number of Folds", y = "MSE",
fill = "Number of Folds") +
theme_classic(base_size = 18) +
theme(plot.title = element_text(hjust = 0.5),
panel.background = element_rect(fill = "floralwhite"),
legend.title = element_text(hjust = 0.5, size = 15),
legend.margin = margin(6, 6, 6, 6))
library(stat302package)
devtools::install_github("yufei-wang/stat302")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(stat302package)
devtools::install_github("yufei-wang/stat302package")
