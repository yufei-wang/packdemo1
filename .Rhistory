points(tan.port$sd, tan.port$er, col="red", pch=16, cex=2)
points(sigma.mat["sbux"], mu.pe, col="darkolivegreen", pch=16, cex=2)
text(tan.port$sd, tan.port$er, labels="TANGENCY", pos=2)
text(sigma.mat["sbux"], mu.pe, labels="efficient portfolio", pos=2)
sr.tan = (tan.port$er - rf)/tan.port$sd
abline(a=rf, b=sr.tan, col="green", lwd=2)
knitr::opts_chunk$set(echo = TRUE)
options(digits=3, width=70)
library(IntroCompFinR)
library(PerformanceAnalytics)
library(tseries)
library(zoo)
library(boot)
library(corrplot)
# change this to the appropriate path on your computer. This is where some data
# will be saved
savePath="/Users/wangyufei/Desktop/project\ for\ 424"
getwd()
setwd("/Users/wangyufei/Desktop/project\ for\ 424")
#
# load data from Yahoo!
#
# get monthly adjusted closing price data on Vanguard mutual fund data from Yahoo
# using the tseries function get.hist.quote. Set sample to December 2009 through
# December 2014. Note: if you are not careful with the start and end dates
# or if you set the retclass to "ts" then results might look weird
asset.names = c("vfinx","veurx","veiex","vbltx","vbisx","vpacx")
start.date = "2014-11-01"
end.date = "2019-11-30"
vfinx.prices = get.hist.quote(instrument="vfinx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
veurx.prices = get.hist.quote(instrument="veurx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
veiex.prices = get.hist.quote(instrument="veiex", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
vbltx.prices = get.hist.quote(instrument="vbltx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
vbisx.prices = get.hist.quote(instrument="vbisx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
vpacx.prices = get.hist.quote(instrument="vpacx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
# change time indices to class yearmon, which is most appropriate for monthly data
index(vfinx.prices) = as.yearmon(index(vfinx.prices))
index(veurx.prices) = as.yearmon(index(veurx.prices))
index(veiex.prices) = as.yearmon(index(veiex.prices))
index(vbltx.prices) = as.yearmon(index(vbltx.prices))
index(vbisx.prices) = as.yearmon(index(vbisx.prices))
index(vpacx.prices) = as.yearmon(index(vpacx.prices))
projectPrices.z = merge(vfinx.prices,veurx.prices,veiex.prices,vbltx.prices,
vbisx.prices,vpacx.prices)
colnames(projectPrices.z) = asset.names
# create data.frame for downloading
projectPrices.df = coredata(projectPrices.z)
rownames(projectPrices.df) = as.character(index(projectPrices.z))
#
# compute cc and simple returns
#
projectReturns.z = diff(log(projectPrices.z))
projectReturnsSimple.z = exp(projectReturns.z) - 1
# create data.frame for downloading
projectReturns.df = as.data.frame(coredata(projectReturns.z))
rownames(projectReturns.df) = as.character(index(projectReturns.z))
projectReturnsSimple.df = as.data.frame(coredata(projectReturnsSimple.z))
rownames(projectReturnsSimple.df) = as.character(index(projectReturnsSimple.z))
#
# Create matrix of return data and compute pairwise scatterplots
#
ret.mat = coredata(projectReturns.z)
pairs(ret.mat, col="cornflowerblue")
#
# compute descriptive statistics
#
muhat.vals = colMeans(projectReturns.z)
muhat.mat = as.matrix(muhat.vals)
sd.vals = apply(projectReturns.z, 2, sd)
skew.vals = apply(projectReturns.z, 2, skewness)
ekurt.vals = apply(projectReturns.z, 2, kurtosis)
cov.mat = var(projectReturns.z)
cor.mat = cov2cor(cov.mat)
covhat.vals = cov.mat[lower.tri(cov.mat)]
rhohat.vals = cor.mat[lower.tri(cor.mat)]
names(covhat.vals) <- names(rhohat.vals) <-
c("vfinx,veurx","vfinx,veiex","vfinx,vbltx", "vfinx,vbisx", "vfinx,vpacx",
"veurx,veiex", "veurx,vbltx", "veurx,vbisx", "veurx,vpacx",
"veiex,vbltx", "veiex,vbisx", "veiex,vpacx",
"vbltx,vbisx", "vbltx,vpacx",
"vbisx,vpacx")
# empirical quantiles for VaR calculations
q.vals = apply(projectReturns.z, 2, quantile, prob=c(0.01,0.05))
# display results in a table
stats.mat = rbind(muhat.vals,
sd.vals,
skew.vals,
ekurt.vals,
q.vals)
rownames(stats.mat) = c("Mean", "Std Dev", "Skewness",
"Excess Kurtosis", "1% Quantile",
"5% Quantile")
# print statistics
stats.mat
#
# compute cc and simple returns
#
projectReturns.z = diff(log(projectPrices.z))
projectReturnsSimple.z = exp(projectReturns.z) - 1
# create data.frame for downloading
projectReturns.df = as.data.frame(coredata(projectReturns.z))
rownames(projectReturns.df) = as.character(index(projectReturns.z))
projectReturnsSimple.df = as.data.frame(coredata(projectReturnsSimple.z))
rownames(projectReturnsSimple.df) = as.character(index(projectReturnsSimple.z))
#
# plot data
#
my.panel <- function(...) {
lines(...)
abline(h=0)
}
plot(projectPrices.z, col="cornflowerblue", lwd=2, main = "Monthly Prices")
plot(projectReturns.z, panel=my.panel, col="cornflowerblue", lwd=2, main = "Monthly Return")
# plot growth of $1 over the five years using PerformanceAnalytics function
# chart.CumReturns
chart.CumReturns(projectReturnsSimple.z, wealth.index=TRUE, legend.loc="topleft",
lwd=2, main="equity curve (growth of $1)")
fourPanelPlot(projectReturns.z[, 1, drop=FALSE])
fourPanelPlot(projectReturns.z[, 2, drop=FALSE])
fourPanelPlot(projectReturns.z[, 3, drop=FALSE])
fourPanelPlot(projectReturns.z[, 4, drop=FALSE])
fourPanelPlot(projectReturns.z[, 5, drop=FALSE])
fourPanelPlot(projectReturns.z[, 6, drop=FALSE])
#
# compute descriptive statistics
#
muhat.vals = colMeans(projectReturns.z)
muhat.mat = as.matrix(muhat.vals)
sd.vals = apply(projectReturns.z, 2, sd)
skew.vals = apply(projectReturns.z, 2, skewness)
ekurt.vals = apply(projectReturns.z, 2, kurtosis)
cov.mat = var(projectReturns.z)
cor.mat = cov2cor(cov.mat)
covhat.vals = cov.mat[lower.tri(cov.mat)]
rhohat.vals = cor.mat[lower.tri(cor.mat)]
names(covhat.vals) <- names(rhohat.vals) <-
c("vfinx,veurx","vfinx,vbisx","vfinx,vbltx", "vfinx,vbisx", "vfinx,vpacx",
"veurx,vbisx", "veurx,vbltx", "veurx,vbisx", "veurx,vpacx",
"vbisx,vbltx", "vbisx,vbisx", "vbisx,vpacx",
"vbltx,vbisx", "vbltx,vpacx",
"vbisx,vpacx")
# empirical quantiles for VaR calculations
q.vals = apply(projectReturns.z, 2, quantile, prob=c(0.01,0.05))
# display results in a table
stats.mat = rbind(muhat.vals,
sd.vals,
skew.vals,
ekurt.vals,
q.vals)
rownames(stats.mat) = c("Mean", "Std Dev", "Skewness",
"Excess Kurtosis", "1% Quantile",
"5% Quantile")
# print statistics
stats.mat
library(cowplot)
# plot return-risk tradeoff and compute Sharpe ratios
#
## risk free rate
rf = 0.005/12
plot(sd.vals, muhat.vals, xlim=c(0, 0.06), ylim=c(0, 0.013),
ylab="Expected Return", xlab="Standard Deviation",
cex=2, pch=16, col="cornflowerblue")
text(sd.vals, muhat.vals, labels=colnames(projectReturns.z),
pos=3)
SharpeRatios = (muhat.vals - rf)/sd.vals
# compute bootstrap standard error
# function to bootstrap VaR
sharpeRatio.boot = function(x, idx, risk.free) {
muhat = mean(x[idx])
sigmahat = sd(x[idx])
sharpeRatio = (muhat - risk.free)/sigmahat
sharpeRatio
}
sharpe.vfinx.boot = boot(ret.mat[, "vfinx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.veurx.boot = boot(ret.mat[, "veurx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.vbisx.boot = boot(ret.mat[, "vbisx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.vbltx.boot = boot(ret.mat[, "vbltx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.vbisx.boot = boot(ret.mat[, "vbisx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.vpacx.boot = boot(ret.mat[, "vpacx"],
statistic=sharpeRatio.boot, R=999, risk.free=rf)
sharpe.vfinx.boot
sharpe.veurx.boot
sharpe.vbisx.boot
sharpe.vbltx.boot
sharpe.vbisx.boot
sharpe.vpacx.boot
boot.vals <- c(sharpe.vfinx.boot, sharpe.veurx.boot, sharpe.vbisx.boot, sharpe.vbltx.boot, sharpe.vbisx.boot, sharpe.vpacx.boot)
boot.sd.vals <- data.frame(sd(sharpe.vfinx.boot$t), sd(sharpe.veurx.boot$t), sd(sharpe.vbisx.boot$t), sd(sharpe.vbltx.boot$t), sd(sharpe.vbisx.boot$t), sd(sharpe.vpacx.boot$t))
boot.sd.vals <- rbind(boot.sd.vals, SharpeRatios)
colnames(boot.sd.vals) <- c("vfinx", "veurx", "vbisx", "vbltx", "vbisx", "vpacx" )
rownames(boot.sd.vals) <- c("std. error", "sharpe ratios")
boot.sd.vals
boot.ci(sharpe.vfinx.boot, conf = 0.95, type = c("norm","perc"))
boot.ci(sharpe.veurx.boot, conf = 0.95, type = c("norm","perc"))
boot.ci(sharpe.vbisx.boot, conf = 0.95, type = c("norm","perc"))
boot.ci(sharpe.vbltx.boot, conf = 0.95, type = c("norm","perc"))
boot.ci(sharpe.vbisx.boot, conf = 0.95, type = c("norm","perc"))
boot.ci(sharpe.vpacx.boot, conf = 0.95, type = c("norm","perc"))
plot(sharpe.vfinx.boot, main = " bootstrap Sharpe Ratio for vfinx ")
plot(sharpe.veurx.boot, main = " bootstrap Sharpe Ratio for veurx ")
plot(sharpe.vbisx.boot, main = " bootstrap Sharpe Ratio for vbisx ")
plot(sharpe.vbltx.boot, main = " bootstrap Sharpe Ratio for vbltx ")
plot(sharpe.vbisx.boot, main = " bootstrap Sharpe Ratio for vbisx ")
plot(sharpe.vpacx.boot, main = " bootstrap Sharpe Ratio for vpacx ")
# compute standard errors and confidence intervals (do it yourself)
muhat.vals = apply(ret.mat, 2, mean)
sigmahat.vals = apply(ret.mat, 2, sd)
muhat.vals
sigmahat.vals
nobs = nrow(ret.mat)
nobs
##standard error of mean
se.muhat = sigmahat.vals/sqrt(nobs)
se.muhat
##standard error of sd
se.sigmahat = sigmahat.vals/sqrt(2*nobs)
se.sigmahat
## confidence interval for mean
mu.lower = muhat.vals - 2*se.muhat
mu.upper = muhat.vals + 2*se.muhat
cbind(mu.lower,mu.upper)
## confidence interval for sd
sigma.lower = sigmahat.vals - 2*se.sigmahat
sigma.upper = sigmahat.vals + 2*se.sigmahat
cbind(sigma.lower,sigma.upper)
##compute annualized sharpe ratios
muhat.vals.annualized <- 12*muhat.vals
sd.vals.annualized <- sqrt(12)*sd.vals
SharpeRatios.annualized = (muhat.vals.annualized - rf)/sd.vals.annualized
##print annualized values and sharpe ratios
rbind(muhat.vals.annualized,sd.vals.annualized,SharpeRatios.annualized)
stats.mat
##ranking assets vs monthly Sharpe ratio
sort(muhat.vals.annualized)
SharpeRatios
growth_annualized <- 1*(1 + muhat.vals.annualized)^5
growth_annualized
pairs(ret.mat, col="cornflowerblue")
cov.mat
cor.mat
corrplot(cor.mat, method="ellipse")
#
# write covariance matrix, expected returns, sd values and quantiles to files
# for importing into Excel
#
write.csv(projectPrices.df, file=paste(savePath, "projectPrices.csv", sep=""))
write.csv(projectReturns.df, file=paste(savePath, "projectReturns.csv", sep=""))
write.csv(projectReturnsSimple.df, file=paste(savePath, "projectReturns.csv", sep=""))
write.csv(cov.mat, file=paste(savePath, "covmat.csv", sep=""))
write.csv(muhat.vals, file=paste(savePath, "muhat.csv", sep=""))
write.csv(sd.vals, file=paste(savePath, "sd.csv", sep=""))
write.csv(t(q.vals), file=paste(savePath, "q.csv", sep=""))
# function to compute normal and empirical VaR for a matrix of returns
Value.at.Risk = function(x, p=0.05, w=100000, method=c("normal", "empirical")) {
method=method[1]
x = as.matrix(x)
if (method == "normal") {
q = apply(x, 2, mean) + apply(x, 2, sd)*qnorm(p)
} else {
q = apply(x, 2, quantile, p)
}
VaR = (exp(q) - 1)*w
VaR
}
# compute 5% and 1% normal VaR for all assets
VaR.normal.05 = Value.at.Risk(ret.mat, p=0.05, method="normal")
VaR.normal.05
VaR.normal.01 = Value.at.Risk(ret.mat, p=0.01)
VaR.normal.01
# write a function to compute the annual normal VaR
# function to bootstrap VaR
ValueAtRisk.05.boot = function(x, idx, p=0.05, w=100000) {
q = mean(x[idx]) + sd(x[idx])*qnorm(p)
VaR = (exp(q) - 1)*w
VaR
}
ValueAtRisk.01.boot = function(x, idx, p=0.01, w=100000) {
q = mean(x[idx]) +  sd(x[idx])*qnorm(p)
VaR = (exp(q) - 1)*w
VaR
}
# bootstrap estimated standard errors for 5% VaR estimates
VaR.05.boot.vfinx = boot(ret.mat[, "vfinx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.vfinx
ci.VaR.05.boot.vfinx <-boot.ci(VaR.05.boot.vfinx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.veurx = boot(ret.mat[, "veurx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.veurx
ci.VaR.05.boot.veurx <- boot.ci(VaR.05.boot.veurx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.vbisx = boot(ret.mat[, "vbisx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.vbisx
ci.VaR.05.boot.vbisx <- boot.ci(VaR.05.boot.vbisx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.vbltx = boot(ret.mat[, "vbltx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.vbltx
ci.VaR.05.boot.vbltx <- boot.ci(VaR.05.boot.vbltx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.vbisx = boot(ret.mat[, "vbisx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.vbisx
ci.VaR.05.boot.vbisx <- boot.ci(VaR.05.boot.vbisx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.vpacx = boot(ret.mat[, "vpacx"],
statistic=ValueAtRisk.05.boot, R=999)
VaR.05.boot.vpacx
ci.VaR.05.boot.vpacx <- boot.ci(VaR.05.boot.vpacx, conf = 0.95, type = c("norm","perc"))
VaR.05.boot.sd.vals <- data.frame(sd(VaR.05.boot.vfinx$t), sd(VaR.05.boot.veurx$t), sd(VaR.05.boot.vbisx$t), sd(VaR.05.boot.vbltx$t), sd(VaR.05.boot.vbisx$t), sd(VaR.05.boot.vpacx$t))
VaR.05.boot.sd.vals <- rbind(VaR.05.boot.sd.vals, VaR.normal.05)
colnames(VaR.05.boot.sd.vals) <- c("vfinx", "veurx", "vbisx", "vbltx", "vbisx", "vpacx" )
rownames(VaR.05.boot.sd.vals) <- c("std. error", "VaR Normal 0.05")
# bootstrap estimated standard errors for 1% VaR estimates
VaR.01.boot.vfinx = boot(ret.mat[, "vfinx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.vfinx
ci.VaR.01.boot.vfinx <- boot.ci(VaR.01.boot.vfinx, conf = 0.95, type = c("norm","perc"))
VaR.01.boot.veurx = boot(ret.mat[, "veurx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.veurx
ci.VaR.01.boot.veurx <- boot.ci(VaR.01.boot.veurx, conf = 0.95, type = c("norm","perc"))
VaR.01.boot.vbisx = boot(ret.mat[, "vbisx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.vbisx
ci.VaR.01.boot.vbisx <- boot.ci(VaR.01.boot.vbisx, conf = 0.95, type = c("norm","perc"))
VaR.01.boot.vbltx = boot(ret.mat[, "vbltx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.vbltx
ci.VaR.01.boot.vbltx <- boot.ci(VaR.01.boot.vbltx, conf = 0.95, type = c("norm","perc"))
VaR.01.boot.vbisx = boot(ret.mat[, "vbisx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.vbisx
ci.VaR.01.boot.vbisx <- boot.ci(VaR.01.boot.vbisx, conf = 0.95, type = c("norm","perc"))
VaR.01.boot.vpacx = boot(ret.mat[, "vpacx"],
statistic=ValueAtRisk.01.boot, R=999)
VaR.01.boot.vpacx
ci.VaR.01.boot.vpacx <- boot.ci(VaR.01.boot.vpacx, conf = 0.95, type = c("norm","perc"))
## making table for bootstrap 1% VaR and bootstrap standard errors
VaR.01.boot.sd.vals <- data.frame(sd(VaR.01.boot.vfinx$t), sd(VaR.01.boot.veurx$t), sd(VaR.01.boot.vbisx$t), sd(VaR.01.boot.vbltx$t), sd(VaR.01.boot.vbisx$t), sd(VaR.01.boot.vpacx$t))
VaR.01.boot.sd.vals <- rbind(VaR.01.boot.sd.vals, VaR.normal.01)
colnames(VaR.01.boot.sd.vals) <- c("vfinx", "veurx", "vbisx", "vbltx", "vbisx", "vpacx" )
rownames(VaR.01.boot.sd.vals) <- c("std. error", "VaR Normal 0.01")
#print table of 1% and 5% VaR estimates with bootstrap standard errors
VaR.05.boot.sd.vals
VaR.01.boot.sd.vals
## plot 1% and 5% VaR estimates with bootstrap standard errors
plot(VaR.05.boot.vfinx)
plot(VaR.05.boot.veurx)
plot(VaR.05.boot.vbisx)
plot(VaR.05.boot.vbltx)
plot(VaR.05.boot.vbisx)
plot(VaR.05.boot.vpacx)
plot(VaR.01.boot.vfinx)
plot(VaR.01.boot.veurx)
plot(VaR.01.boot.vbisx)
plot(VaR.01.boot.vbltx)
plot(VaR.01.boot.vbisx)
plot(VaR.01.boot.vpacx)
##table for 95% CI for 5% VaR estimates
ci.VaR.05.boot.vals <- rbind(ci.VaR.05.boot.vfinx$normal,ci.VaR.05.boot.veurx$normal, ci.VaR.05.boot.vbisx$normal,ci.VaR.05.boot.vbltx$normal,ci.VaR.05.boot.vbisx$normal,ci.VaR.05.boot.vpacx$normal)
rownames(ci.VaR.05.boot.vals) <- c("vfinx", "veurx", "vbisx", "vbltx", "vbisx", "vpacx" )
colnames(ci.VaR.05.boot.vals) <- c("conf", "lower bound", "upper bound")
ci.VaR.05.boot.vals
##table for 95% CI for 1% VaR estimates
ci.VaR.01.boot.vals <- rbind(ci.VaR.01.boot.vfinx$normal,ci.VaR.01.boot.veurx$normal, ci.VaR.01.boot.vbisx$normal,ci.VaR.01.boot.vbltx$normal,ci.VaR.01.boot.vbisx$normal,ci.VaR.01.boot.vpacx$normal)
rownames(ci.VaR.01.boot.vals) <- c("vfinx", "veurx", "vbisx", "vbltx", "vbisx", "vpacx" )
colnames(ci.VaR.01.boot.vals) <- c("conf", "lower bound", "upper bound")
#compute annual normal VaR
Value.at.Risk.annualized = function(x, p=0.05, w=100000, method=c("normal", "empirical")) {
method=method[1]
x = as.matrix(x)
if (method == "normal") {
q = apply(x*12, 2, mean) +  apply(sqrt(12)*x, 2, sd)*qnorm(p)
} else {
q = apply(x*12, 2, quantile, p)
}
VaR = (exp(q) - 1)*w
VaR
}
Value.at.Risk.annualized(ret.mat, p=0.01)
Value.at.Risk.annualized(ret.mat, p=0.05)
# vfinx
roll.muhat = rollapply(projectReturns.z[,"vfinx",drop=FALSE], width=24,
FUN=mean, align="right")
roll.sigmahat = rollapply(projectReturns.z[,"vfinx",drop=FALSE], width=24,
FUN=sd, align="right")
plot(merge(roll.muhat, roll.sigmahat, projectReturns.z[,"vfinx",drop=FALSE]),
plot.type="single",
main="24 month rolling estimates: Vfinx",ylab="returns",
lwd=2, col=c("cornflowerblue","orange", "black"))
abline(h=0)
legend(x="bottomright",legend=c("Rolling mean","Rolling sd", "Monthly returns"),
lwd=2, col=c("cornflowerblue","orange","black"))
# rolling correlations
rhohat = function(x) {
cor(x)[1,2]
}
#veurx
roll.muhat = rollapply(projectReturns.z[,"veurx",drop=FALSE], width=24,
FUN=mean, align="right")
roll.sigmahat = rollapply(projectReturns.z[,"veurx",drop=FALSE], width=24,
FUN=sd, align="right")
plot(merge(roll.muhat, roll.sigmahat, projectReturns.z[,"veurx",drop=FALSE]),
plot.type="single",
main="24 month rolling estimates: Veurx",ylab="returns",
lwd=2, col=c("cornflowerblue","orange", "black"))
abline(h=0)
legend(x="bottomright",legend=c("Rolling mean","Rolling sd", "Monthly returns"),
lwd=2, col=c("cornflowerblue","orange","black"))
#vbltx
roll.muhat = rollapply(projectReturns.z[,"vbltx",drop=FALSE], width=24,
FUN=mean, align="right")
roll.sigmahat = rollapply(projectReturns.z[,"vbltx",drop=FALSE], width=24,
FUN=sd, align="right")
plot(merge(roll.muhat, roll.sigmahat, projectReturns.z[,"vbltx",drop=FALSE]),
plot.type="single",
main="24 month rolling estimates: Vbltx",ylab="returns",
lwd=2, col=c("cornflowerblue","orange", "black"))
abline(h=0)
legend(x="bottomright",legend=c("Rolling mean","Rolling sd", "Monthly returns"),
lwd=2, col=c("cornflowerblue","orange","black"))
#vbisx
roll.muhat = rollapply(projectReturns.z[,"vbisx",drop=FALSE], width=24,
FUN=mean, align="right")
roll.sigmahat = rollapply(projectReturns.z[,"vbisx",drop=FALSE], width=24,
FUN=sd, align="right")
plot(merge(roll.muhat, roll.sigmahat, projectReturns.z[,"vbisx",drop=FALSE]),
plot.type="single",
main="24 month rolling estimates: Vbisx",ylab="returns",
lwd=2, col=c("cornflowerblue","orange", "black"))
abline(h=0)
legend(x="bottomright",legend=c("Rolling mean","Rolling sd", "Monthly returns"),
lwd=2, col=c("cornflowerblue","orange","black"))
#vpacx
roll.muhat = rollapply(projectReturns.z[,"vpacx",drop=FALSE], width=24,
FUN=mean, align="right")
roll.sigmahat = rollapply(projectReturns.z[,"vpacx",drop=FALSE], width=24,
FUN=sd, align="right")
plot(merge(roll.muhat, roll.sigmahat, projectReturns.z[,"vpacx",drop=FALSE]),
plot.type="single",
main="24 month rolling estimates: Vpacx",ylab="returns",
lwd=2, col=c("cornflowerblue","orange", "black"))
abline(h=0)
legend(x="bottomright",legend=c("Rolling mean","Rolling sd", "Monthly returns"),
lwd=2, col=c("cornflowerblue","orange","black"))
knitr::opts_chunk$set(echo = TRUE)
options(digits=3, width=70)
library(IntroCompFinR)
library(PerformanceAnalytics)
library(tseries)
library(zoo)
library(boot)
library(corrplot)
library(knitr)
library(kableExtra)
# change this to the appropriate path on your computer. This is where some data
# will be saved
savePath="/Users/wangyufei/Desktop/project\ for\ 424"
getwd()
setwd("/Users/wangyufei/Desktop/project\ for\ 424")
#
# load data from Yahoo!
#
# get monthly adjusted closing price data on Vanguard mutual fund data from Yahoo
# using the tseries function get.hist.quote. Set sample to December 2009 through
# December 2014. Note: if you are not careful with the start and end dates
# or if you set the retclass to "ts" then results might look weird
asset.names = c("vfinx","veurx","veiex","vbltx","vbisx","vpacx")
start.date = "2014-11-01"
end.date = "2019-11-30"
vfinx.prices = get.hist.quote(instrument="vfinx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
veurx.prices = get.hist.quote(instrument="veurx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
veiex.prices = get.hist.quote(instrument="veiex", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
vbltx.prices = get.hist.quote(instrument="vbltx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
vbisx.prices = get.hist.quote(instrument="vbisx", start=start.date,
end=end.date, quote="AdjClose",
provider="yahoo", origin="1970-01-01",
compression="m", retclass="zoo")
a
